---
title: "DATA607 Week 7 Assignment"
author: "Gabriel Campos"
date: "`r format(Sys.Date(), '%B %d %Y')`"
output: 
  html_document:
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: cerulean
    toc: true
    toc_float: true
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, results = "hold")
library(rvest)
library(dplyr)
library(XML)
library(RCurl)
library(janitor)
library(stringr)
library(kableExtra)
```

Overview
========

1. Pick **three** of your favorite books on **one** of your favorite subjects. 
    + **At least one** of the books should have **more than one author**. 
2. For **each book**, include the **title**, **authors**, and **two or three** other **attributes** that you find interesting.
3. Take the information that you’ve selected about these three books, and separately **create three files** which store the book’s information in **HTML** (using an **html table**), **XML**, and **JSON formats** (**e.g.** $“books.html”, “books.xml”, and “books.json”$).
4. To help you better understand the different file structures, I’d prefer that you **create each of these files “by hand”** unless you’re already very comfortable with the file formats.
5. Write `R` code, using **your** `packages` of choice, to **load the information** from each of the **three sources** into separate `R` `data frames`. 
    + **Are the three data frames identical?**
6. Your **deliverable** is the **three source files** and the `R` **code**.
    + If you can, `package` your assignment solution up into an `.Rmd` file and **publish** to $rpubs.com$.       * [This will also require finding a way to make your three text files accessible from the web].

Import Data
===========

Files `book.html`, `book.xml` & `book.json` are located in [Week 7 Folder](https://github.com/gcampos100/DATA607Spring2021/tree/main/Week%207) of my [GitHub Repository](https://github.com/gcampos100/DATA607Spring2021)

All url's were stored to there respective character variable:

* import_HTML
* import_XML
* import_JSON

```{r, include=FALSE}
url_HTML  <-"https://raw.githubusercontent.com/gcampos100/DATA607Spring2021/main/Week%207/book.html"
urlXML    <-httr::GET("https://raw.githubusercontent.com/gcampos100/DATA607Spring2021/main/Week%207/book.xml")
url_JSON  <-"https://raw.githubusercontent.com/gcampos100/DATA607Spring2021/main/Week%207/book.json"
```

Importing involve the following

+ **HTML:** `read_html()` from the `rvest` library, and is imported as class [XMLInternalDocument](https://www.rdocumentation.org/packages/XML/versions/3.99-0.5/topics/XMLInternalDocument-class)
+ **XML:** `xmlParse()` from the `XML` library and is imported as class [xml_document](https://www.rdocumentation.org/packages/xml2/versions/1.3.2/topics/xml_document-class)
+ **JSON:** `fromJSON()` from the `jsonlite` library imported as a [list](https://www.tutorialspoint.com/r/r_lists.htm)

```{r}
import_html <-read_html(url_HTML, header = TRUE)
import_xml <- xmlParse(urlXML)
import_json <-jsonlite::fromJSON(url_JSON)
```

Convert to Data Frame
=====================

* **HTML:** converted to first with `html_table()` function, the resulting [tibble](https://blog.rstudio.com/2016/03/24/tibble-1-0-0/#:~:text=There%20are%20two%20main%20differences,to%20work%20with%20large%20data.) is then converted to a traditional `data.frame` with the function `as.data.frame()`. **NOTE**[^1]$^,$ [^2]
* **XML:** `xmlToDataFrame` function from `XML` package.**NOTE**[^3]
* **JSON** `do.call` **base** function is used to utilize a [function  call](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/do.call) in this operation `rbind()` on list. `lapply()` is used for performing functions on a list, in this case formatting the list into rows and columns. The combined methods create the desired `data.frame`



```{r}
df_html<-
  as.data.frame(html_table(import_html)) %>%
    row_to_names(1) %>%
      tibble::remove_rownames()

df_xml<-xmlToDataFrame(import_xml)
colnames(df_xml)<-  str_to_title(colnames(df_xml))


df_json <- do.call("rbind", lapply(import_json, data.frame))
  rownames(df_json)<-NULL
```


```{r, echo= FALSE}
df_html %>%
  kbl()   %>%
    add_header_above(c("HTML" = 5))
```

```{r, echo=FALSE}
df_xml %>%
  kbl()  %>%
    add_header_above(c("XML" = 5))
```

```{r, echo=FALSE}
df_json %>%
  kbl() %>%
    add_header_above(c("JSON" = 5))
```

Conclusion
==========

**Are the three data frames identical?**

No, they are not. The column names are imported according the the naming conventions of where they were imported (although can be excluded or altered on import). Each requires their own library to import and the class types of each on import is distinct. As such, the approach to changing the data into a data.frame are also different.

[^1]:*when examined with `class()` function, the result of `html_table(import_html)` is class type `list`.*:
[^2]:*`row_to_names` function used to replace column names with first row values.*:
[^3]:*`str_to_title` used to capitalized the first letter of each column word.*: