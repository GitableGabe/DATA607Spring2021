---
title: "DATA607 Project 4"
author: "Gabriel Campos"
date: "`r format(Sys.Date(), '%B %d %Y')`"
output:
  html_document:
    code_folding: "show"
    includes:
      in_header: header.html
    css: ./lab.css
    highlight: pygments
    theme: readable
    toc: true
    toc_float: true
  prettydoc::html_pretty:
    theme: cayman
  pdf_document: default
editor_options: 
  chunk_output_type: console
---


<!--match.arg(theme, themes()) : 
    'arg' should be one of "default", "cerulean", "journal","flatly",
    "darkly", "readable", "spacelab", "united", "cosmo", "lumen", "paper", 
    "sandstone", "simplex", "yeti"  -------->

```{r, echo=FALSE,warning=FALSE, results='hide', include=FALSE}
library(tidyverse)
library(dplyr)
library(reactable)
library(kableExtra)
library(stringr)
library(magrittr)
library(downloader)
```

<!-- (https://rdrr.io/cran/reactable/man/reactable.html) -->

# Assignment{.tabset}

## Requirements

It can be useful to be able to classify new "test" documents using already classified "training"
documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to 
predict whether or not a new document is spam.  

For this project, you can start with a spam/ham dataset, then predict the class of new documents
(either withheld from the training dataset or from another source such as your own spam folder).
[Example corpus.](https://spamassassin.apache.org/old/publiccorpus/)

Here are two short videos that you may find helpful.

<iframe width="560" height="315" src="https://www.youtube.com/embed/6IzhRaSePKU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The second video provides a short overview of predictive classifiers.

<iframe width="560" height="315" src="https://www.youtube.com/embed/5ikDo4SrLNQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

For more adventurous students, you are welcome (encouraged!) to come up with a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.

**New!  Project 4 extra credit!**  Students who use the relatively new tidymodels and textrecipes packages to complete their Project 4 work will automatically receive 5 extra credit points.  tidymodels is a significant improvement over Max Kuhn's older `caret` package.  Here are some resources to help you get up to speed on tidymodels and textrecipes.

* [Tidy Modeling with R, Max Kuhn and Julia Silge](https://www.tmwr.org/). Julia Silge has also done a number of tidymodels screencasts, including [here](https://www.youtube.com/watch?v=BgWCuyrwD1s)
* [github.com/tidymodels/textrecipes](https://github.com/tidymodels/textrecipes)
* DataCamp course, [Modeling with TidyModels in R](https://learn.datacamp.com/courses/modeling-with-tidymodels-in-r)

## Load Data

URL of file and filename is set by `URL_easy_ham` and `tar_easy_ham` respectively.

```{r}
#easy_ham.tar.bz2 import
URL_easy_ham = 
  "http://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2"
tar_easy_ham = "20021010_easy_ham.tar.bz2"
dir_easy_ham      = "unzipped_files\\easy_ham\\"

URL_spam = 
  "http://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2"
tar_spam     = "20021010_spam.tar.bz2"
dir_spam     = "unzipped_files\\spam\\"
```

The functions [`download.file()`](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/download.file) and [`untar()`](https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/untar) is used to download the tar file. The function [`list.files`](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/list.files) is used with the variable `ham_dir` specified above to import the individual files for `20021010_easy_ham.tar.bz2`.

```{r class.source = "fold-hide", warning=FALSE, echo=TRUE}
# ham zip file download
download.file(url = URL_easy_ham, destfile = tar_easy_ham)
untar(tar_easy_ham, exdir="unzipped_files", compressed = "bzip2")
files_easy_ham = list.files(path = dir_easy_ham,full.names = TRUE)

# spam zip file download
download.file(url = URL_spam, destfile = tar_spam)
untar(tar_spam, exdir="unzipped_files", compressed = "bzip2")
files_spam = list.files(path = dir_spam,full.names = TRUE)
```

`list.files` is also used with several piping functions (`%>%`) to create a data frame with `email_ID`, `text`, `class`, and `double` value `spam` column as shown below

```{r}
df_easy_ham <-
  list.files(path = dir_easy_ham) %>%
    as.data.frame() %>%
      set_colnames("email_ID") %>%
        mutate(text = lapply(files_easy_ham, read_lines)) %>%
          unnest(c(text)) %>%
            mutate(class = "ham",
                  spam = 0) %>%
                    group_by(email_ID) %>%
            mutate(text = paste(text, collapse = " ")) %>%
                            ungroup() %>%
                              distinct()
```

```{r, echo=FALSE}
head(easy_ham,5)

```

```{r}
df_spam <-
  list.files(path = dir_spam) %>%
    as.data.frame() %>%
      set_colnames("email_ID") %>%
        mutate(text = lapply(files_spam, read_lines)) %>%
          unnest(c(text)) %>%
            mutate(class = "spam",
                  spam = 1) %>%
                    group_by(email_ID) %>%
            mutate(text = paste(text, collapse = " ")) %>%
                            ungroup() %>%
                              distinct()
```

```{r}
easy_ham$text[1:2]
```


## Training Data

```{r}
df_easy_ham_spam <- rbind(df_easy_ham, df_spam)

```



<!------- Below is for removing excessive space in Rmarkdown | HTML formatting -------->

<div class="tocify-extend-page" data-unique="tocify-extend-page" style="height: 0;"></div>